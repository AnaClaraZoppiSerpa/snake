{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pygame\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "# our classes\n",
    "from agentLFA import AgentLFA, QLearningAgentLFA\n",
    "from environment import Environment\n",
    "from screen import Screen\n",
    "\n",
    "# define environment\n",
    "ACTION_SPACE = np.eye(3)\n",
    "NUM_ACTIONS = 3\n",
    "NUM_STATES = 2 ** 11\n",
    "\n",
    "\n",
    "# Set options to activate or deactivate the game view, and its speed\n",
    "pygame.font.init()\n",
    "\n",
    "\n",
    "def plot_metrics(metrics, filepath=None):\n",
    "    formatted_dict = {'episodes': [],\n",
    "                      'metrics': [],\n",
    "                      'results': []}\n",
    "\n",
    "    n = len(metrics['episodes'])\n",
    "    for i in range(n):\n",
    "        episode = metrics['episodes'][i]\n",
    "        score = metrics['scores'][i]\n",
    "        reward = metrics['rewards'][i]\n",
    "\n",
    "        formatted_dict['episodes'].append(episode)\n",
    "        formatted_dict['metrics'].append('score')\n",
    "        formatted_dict['results'].append(score)\n",
    "\n",
    "        formatted_dict['episodes'].append(episode)\n",
    "        formatted_dict['metrics'].append('reward')\n",
    "        formatted_dict['results'].append(reward)\n",
    "\n",
    "    df_metrics = pd.DataFrame(formatted_dict)\n",
    "    sns.lineplot(data=df_metrics, x='episodes', y='results', hue='metrics')\n",
    "    if filepath is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(filepath)\n",
    "\n",
    "def decode_state(encoded_state):\n",
    "    \"\"\"\n",
    "    Decode a binary representation of a state into its decimal base;\n",
    "\n",
    "    encoded_state: an array of 0s and 1s representing a binary value\n",
    "\n",
    "    return: decimal value\n",
    "    \"\"\"\n",
    "    decoded = ''\n",
    "    for s in encoded_state:\n",
    "        decoded += str(s)\n",
    "\n",
    "    return int(decoded, 2)\n",
    "\n",
    "def decode_action(encoded_action):\n",
    "    if isinstance(encoded_action, np.ndarray):\n",
    "        return encoded_action.argmax()\n",
    "    return encoded_action\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: PYDEVD_USE_CYTHON environment variable is set to 'NO'. Frame evaluator will be also disabled because it requires Cython extensions to be enabled in order to operate correctly.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-74eac0e40a24>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 105\u001B[0;31m \u001B[0mmetrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrun_q_learning\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mqLearningAgent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward_function\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdefault_reward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepisodes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m200\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mspeed\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdisplay\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    106\u001B[0m \u001B[0mend\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-2-74eac0e40a24>\u001B[0m in \u001B[0;36mrun_q_learning\u001B[0;34m(agent, reward_function, episodes, display, speed, verbose)\u001B[0m\n\u001B[1;32m     47\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     48\u001B[0m             \u001B[0;31m# Getting the next state, reward\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 49\u001B[0;31m             \u001B[0mstate2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     50\u001B[0m             \u001B[0;31m#state2 = decode_state(state2)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[0;31m# Choosing the next action\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/mestrado/reinforcement_learning/snake/environment.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, action)\u001B[0m\n\u001B[1;32m     39\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_move\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgame\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfood\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_state\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m         \u001B[0mreward\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_reward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m         \u001B[0mdone\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgame\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcrash\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreward\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-2-74eac0e40a24>\u001B[0m in \u001B[0;36mdefault_reward\u001B[0;34m(env)\u001B[0m\n\u001B[1;32m      9\u001B[0m     \"\"\"\n\u001B[1;32m     10\u001B[0m     \u001B[0mreward\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgame\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcrash\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m         \u001B[0mreward\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meaten\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-2-74eac0e40a24>\u001B[0m in \u001B[0;36mdefault_reward\u001B[0;34m(env)\u001B[0m\n\u001B[1;32m      9\u001B[0m     \"\"\"\n\u001B[1;32m     10\u001B[0m     \u001B[0mreward\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0;32mif\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgame\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcrash\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m         \u001B[0mreward\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0menv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mplayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meaten\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Downloads/pycharm-professional-2020.1/pycharm-2020.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mtrace_dispatch\u001B[0;34m(self, frame, event, arg)\u001B[0m\n\u001B[1;32m    719\u001B[0m                 \u001B[0;31m# if thread has a suspend flag, we suspend with a busy wait\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    720\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0minfo\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpydev_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mSTATE_SUSPEND\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 721\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    722\u001B[0m                     \u001B[0;31m# No need to reset frame.f_trace to keep the same trace function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    723\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrace_dispatch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Downloads/pycharm-professional-2020.1/pycharm-2020.1/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 144\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m     \u001B[0;31m# IFDEF CYTHON\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Downloads/pycharm-professional-2020.1/pycharm-2020.1/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[1;32m   1101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1102\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1103\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1105\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Downloads/pycharm-professional-2020.1/pycharm-2020.1/plugins/python/helpers/pydev/pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[1;32m   1116\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1117\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1118\u001B[0;31m                 \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.01\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1119\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1120\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def default_reward(env):\n",
    "    \"\"\"\n",
    "    Return the reward.\n",
    "    The reward is:\n",
    "        -10 when Snake crashes.\n",
    "        +10 when Snake eats food\n",
    "        0 otherwise\n",
    "    \"\"\"\n",
    "    reward = 0\n",
    "    if env.game.crash:\n",
    "        reward = -10\n",
    "    elif env.player.eaten:\n",
    "        reward = 10\n",
    "\n",
    "    return reward\n",
    "\n",
    "def run_q_learning(agent: AgentLFA, reward_function, episodes, display, speed, verbose=True):\n",
    "    # setting random seed\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    if display:\n",
    "        pygame.init()\n",
    "\n",
    "    env = Environment(440, 440, reward_function)\n",
    "    screen = Screen(env)\n",
    "\n",
    "    episode = 0\n",
    "    metrics = {'episodes': [],\n",
    "               'scores': [],\n",
    "               'rewards': []}\n",
    "    start = time.time()\n",
    "    while episode < episodes:\n",
    "        if display:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    quit()\n",
    "\n",
    "            screen.display()\n",
    "\n",
    "        state1, done = env.reset()\n",
    "        #state1 = decode_state(state1)\n",
    "        action1 = agent.choose_action(state1)\n",
    "        episode_reward = 0\n",
    "        while not done:\n",
    "            # Getting the next state, reward\n",
    "            state2, reward, done = env.step(action1)\n",
    "            #state2 = decode_state(state2)\n",
    "            # Choosing the next action\n",
    "            action2 = agent.choose_action(state2)\n",
    "\n",
    "            # Learning the Q-value\n",
    "            decoded_action1 = decode_action(action1)\n",
    "            decoded_action2 = decode_action(action2)\n",
    "\n",
    "            #Calculating Target\n",
    "            future_actions = []\n",
    "            for a in range(agent.num_actions):\n",
    "                future_actions.append(agent.state_value_function(state2,a))\n",
    "\n",
    "            target = reward + agent.gamma*max(future_actions)\n",
    "\n",
    "            #agent.update(state1, state2, reward, decoded_action1, decoded_action2)\n",
    "            agent.update(target, state1, decoded_action1)\n",
    "\n",
    "            state1 = state2\n",
    "            action1 = action2\n",
    "            episode_reward += reward\n",
    "\n",
    "            if display:\n",
    "                screen.display()\n",
    "                pygame.time.wait(speed)\n",
    "\n",
    "            end = time.time()\n",
    "            diff = end - start\n",
    "            if diff > 600: # 10min\n",
    "                break\n",
    "\n",
    "        episode += 1\n",
    "        if verbose:\n",
    "            print(f'Game {episode}      Score: {env.game.score}')\n",
    "\n",
    "        mean_reward = episode_reward/episodes\n",
    "        metrics['episodes'].append(episode)\n",
    "        metrics['rewards'].append(mean_reward)\n",
    "        metrics['scores'].append(env.game.score)\n",
    "\n",
    "        end = time.time()\n",
    "        diff = end - start\n",
    "        if diff > 600: # 10min\n",
    "            break\n",
    "\n",
    "\n",
    "    return metrics\n",
    "\n",
    "N0 = 50\n",
    "gamma = 0.5\n",
    "\n",
    "# define agent\n",
    "qLearningAgent = QLearningAgentLFA(N0, gamma, NUM_STATES, NUM_ACTIONS, ACTION_SPACE)\n",
    "\n",
    "start = time.time()\n",
    "metrics = run_q_learning(qLearningAgent, reward_function=default_reward, episodes=200, speed=0, display=True)\n",
    "end = time.time()\n",
    "\n",
    "plot_metrics(metrics, filepath=None)\n",
    "\n",
    "print('Run time:', (end-start), 'seconds')\n",
    "print('Max. Score:', max(metrics['scores']))\n",
    "print('Mean Last Scores:', np.mean(metrics['scores'][-50:]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configurações gerais para a execução dos modelos:\n",
    "\n",
    "* O espaço de ações é denifido como uma matriz identidade 3x3\n",
    "* Há três ações possíveis (continuar na mesma direção, virar para a esquerda, virar para a direita)\n",
    "* Como cada estado é representado por um vetor binário de 11 posições, ao todo há 2^11 estados possíveis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A função de recompensa padrão é definida como:\n",
    "    \n",
    "* Ganha 10 pontos por comer a maçã\n",
    "* Perde 10 pontos por morrer\n",
    "* Recompensa 0 caso contrário"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q-Learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Experimento 1: Baseline\n",
    "\n",
    "* N0 = 1\n",
    "* gamma = 1\n",
    "* número de episódios = 150"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}